{"PAWS-X": {"description": "\nThe task consists in identifying whether the two sentences in a pair are semantically equivalent or not.\nThe train set includes 49.4k examples, the dev and test sets each comprises nearly 2k examples.\n\nFLUE is an evaluation setup for French NLP systems similar to the popular GLUE benchmark.\nThe goal is to enable further reproducible experiments in the future and to share models and progress on the French language.\nThe tasks and data are obtained from existing works, please refer to our Flaubert paper for a complete list of references.\n", "citation": "\n@inproceedings{pawsx2019emnlp,\n  title = {{PAWS-X: A Cross-lingual Adversarial Dataset for Paraphrase Identification}},\n  author = {Yang, Yinfei and Zhang, Yuan and Tar, Chris and Baldridge, Jason},\n  booktitle = {Proc. of EMNLP},\n  year = {2019}\n}\n\n@misc{le2019flaubert,\n    title={FlauBERT: Unsupervised Language Model Pre-training for French},\n    author={Hang Le and Lo\u00efc Vial and Jibril Frej and Vincent Segonne and Maximin Coavoux and Benjamin Lecouteux and Alexandre Allauzen and Beno\u00eet Crabb\u00e9 and Laurent Besacier and Didier Schwab},\n    year={2019},\n    eprint={1912.05372},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}\n", "homepage": "https://github.com/getalp/Flaubert/tree/master/flue", "license": "", "features": {"sentence1": {"dtype": "string", "id": null, "_type": "Value"}, "sentence2": {"dtype": "string", "id": null, "_type": "Value"}, "label": {"dtype": "int32", "id": null, "_type": "Value"}}, "supervised_keys": null, "builder_name": "flue", "config_name": "PAWS-X", "version": {"version_str": "0.0.0", "description": null, "nlp_version_to_prepare": null, "major": 0, "minor": 0, "patch": 0}, "splits": {"train": {"name": "train", "num_bytes": 12900389, "num_examples": 49401, "dataset_name": "flue"}, "validation": {"name": "validation", "num_bytes": 517031, "num_examples": 2000, "dataset_name": "flue"}, "test": {"name": "test", "num_bytes": 519101, "num_examples": 2000, "dataset_name": "flue"}}, "download_checksums": {"https://storage.googleapis.com/paws/pawsx/x-final.tar.gz": {"num_bytes": 30282057, "checksum": "4146db499101d66e68ae4c8ed3cf9dadecd625f44b7d8cf3d4a0fe93afc4fd9f"}}, "download_size": 30282057, "dataset_size": 13936521, "size_in_bytes": 44218578}, "CLS.books": {"description": "\nThis is a binary classification task.\nIt consists in classifying Amazon reviews for three product categories: books, DVD, and music.\nEach sample contains a review text and the associated rating from 1 to 5 stars.\nReviews rated above 3 is labeled as positive, and those rated less than 3 is labeled as negative.\nThe train and test sets are balanced, including around 1k positive and 1k negative reviews for a total of 2k reviews in each dataset.\n\nFLUE is an evaluation setup for French NLP systems similar to the popular GLUE benchmark.\nThe goal is to enable further reproducible experiments in the future and to share models and progress on the French language.\nThe tasks and data are obtained from existing works, please refer to our Flaubert paper for a complete list of references.\n", "citation": "\n@inproceedings{prettenhofer2010cross,\n  title={Cross-language text classification using structural correspondence learning},\n  author={Prettenhofer, Peter and Stein, Benno},\n  booktitle={Proceedings of the 48th annual meeting of the association for computational linguistics},\n  pages={1118--1127},\n  year={2010}\n}\n\n@misc{le2019flaubert,\n    title={FlauBERT: Unsupervised Language Model Pre-training for French},\n    author={Hang Le and Lo\u00efc Vial and Jibril Frej and Vincent Segonne and Maximin Coavoux and Benjamin Lecouteux and Alexandre Allauzen and Beno\u00eet Crabb\u00e9 and Laurent Besacier and Didier Schwab},\n    year={2019},\n    eprint={1912.05372},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}\n", "homepage": "https://github.com/getalp/Flaubert/tree/master/flue", "license": "", "features": {"text": {"dtype": "string", "id": null, "_type": "Value"}, "label": {"num_classes": 2, "names": ["neg", "pos"], "names_file": null, "id": null, "_type": "ClassLabel"}}, "supervised_keys": null, "builder_name": "flue", "config_name": "CLS.books", "version": {"version_str": "0.0.0", "description": null, "nlp_version_to_prepare": null, "major": 0, "minor": 0, "patch": 0}, "splits": {"train": {"name": "train", "num_bytes": 1241796, "num_examples": 2000, "dataset_name": "flue"}, "test": {"name": "test", "num_bytes": 1227582, "num_examples": 2000, "dataset_name": "flue"}}, "download_checksums": {"https://zenodo.org/record/3251672/files/cls-acl10-unprocessed.tar.gz": {"num_bytes": 314687066, "checksum": "51504dea54dfad525ec5373db0606a263393feb9182ffc50c276682936e14ee5"}}, "download_size": 314687066, "dataset_size": 2469378, "size_in_bytes": 317156444}, "CLS.dvd": {"description": "\nThis is a binary classification task.\nIt consists in classifying Amazon reviews for three product categories: books, DVD, and music.\nEach sample contains a review text and the associated rating from 1 to 5 stars.\nReviews rated above 3 is labeled as positive, and those rated less than 3 is labeled as negative.\nThe train and test sets are balanced, including around 1k positive and 1k negative reviews for a total of 2k reviews in each dataset.\n\nFLUE is an evaluation setup for French NLP systems similar to the popular GLUE benchmark.\nThe goal is to enable further reproducible experiments in the future and to share models and progress on the French language.\nThe tasks and data are obtained from existing works, please refer to our Flaubert paper for a complete list of references.\n", "citation": "\n@inproceedings{prettenhofer2010cross,\n  title={Cross-language text classification using structural correspondence learning},\n  author={Prettenhofer, Peter and Stein, Benno},\n  booktitle={Proceedings of the 48th annual meeting of the association for computational linguistics},\n  pages={1118--1127},\n  year={2010}\n}\n\n@misc{le2019flaubert,\n    title={FlauBERT: Unsupervised Language Model Pre-training for French},\n    author={Hang Le and Lo\u00efc Vial and Jibril Frej and Vincent Segonne and Maximin Coavoux and Benjamin Lecouteux and Alexandre Allauzen and Beno\u00eet Crabb\u00e9 and Laurent Besacier and Didier Schwab},\n    year={2019},\n    eprint={1912.05372},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}\n", "homepage": "https://github.com/getalp/Flaubert/tree/master/flue", "license": "", "features": {"text": {"dtype": "string", "id": null, "_type": "Value"}, "label": {"num_classes": 2, "names": ["neg", "pos"], "names_file": null, "id": null, "_type": "ClassLabel"}}, "supervised_keys": null, "builder_name": "flue", "config_name": "CLS.dvd", "version": {"version_str": "0.0.0", "description": null, "nlp_version_to_prepare": null, "major": 0, "minor": 0, "patch": 0}, "splits": {"train": {"name": "train", "num_bytes": 1233139, "num_examples": 2000, "dataset_name": "flue"}, "test": {"name": "test", "num_bytes": 1249020, "num_examples": 2000, "dataset_name": "flue"}}, "download_checksums": {"https://zenodo.org/record/3251672/files/cls-acl10-unprocessed.tar.gz": {"num_bytes": 314687066, "checksum": "51504dea54dfad525ec5373db0606a263393feb9182ffc50c276682936e14ee5"}}, "download_size": 314687066, "dataset_size": 2482159, "size_in_bytes": 317169225}, "CLS.music": {"description": "\nThis is a binary classification task.\nIt consists in classifying Amazon reviews for three product categories: books, DVD, and music.\nEach sample contains a review text and the associated rating from 1 to 5 stars.\nReviews rated above 3 is labeled as positive, and those rated less than 3 is labeled as negative.\nThe train and test sets are balanced, including around 1k positive and 1k negative reviews for a total of 2k reviews in each dataset.\n\nFLUE is an evaluation setup for French NLP systems similar to the popular GLUE benchmark.\nThe goal is to enable further reproducible experiments in the future and to share models and progress on the French language.\nThe tasks and data are obtained from existing works, please refer to our Flaubert paper for a complete list of references.\n", "citation": "\n@inproceedings{prettenhofer2010cross,\n  title={Cross-language text classification using structural correspondence learning},\n  author={Prettenhofer, Peter and Stein, Benno},\n  booktitle={Proceedings of the 48th annual meeting of the association for computational linguistics},\n  pages={1118--1127},\n  year={2010}\n}\n\n@misc{le2019flaubert,\n    title={FlauBERT: Unsupervised Language Model Pre-training for French},\n    author={Hang Le and Lo\u00efc Vial and Jibril Frej and Vincent Segonne and Maximin Coavoux and Benjamin Lecouteux and Alexandre Allauzen and Beno\u00eet Crabb\u00e9 and Laurent Besacier and Didier Schwab},\n    year={2019},\n    eprint={1912.05372},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}\n", "homepage": "https://github.com/getalp/Flaubert/tree/master/flue", "license": "", "features": {"text": {"dtype": "string", "id": null, "_type": "Value"}, "label": {"num_classes": 2, "names": ["neg", "pos"], "names_file": null, "id": null, "_type": "ClassLabel"}}, "supervised_keys": null, "builder_name": "flue", "config_name": "CLS.music", "version": {"version_str": "0.0.0", "description": null, "nlp_version_to_prepare": null, "major": 0, "minor": 0, "patch": 0}, "splits": {"train": {"name": "train", "num_bytes": 1363857, "num_examples": 2000, "dataset_name": "flue"}, "test": {"name": "test", "num_bytes": 1361338, "num_examples": 2000, "dataset_name": "flue"}}, "download_checksums": {"https://zenodo.org/record/3251672/files/cls-acl10-unprocessed.tar.gz": {"num_bytes": 314687066, "checksum": "51504dea54dfad525ec5373db0606a263393feb9182ffc50c276682936e14ee5"}}, "download_size": 314687066, "dataset_size": 2725195, "size_in_bytes": 317412261}, "XNLI": {"description": "\nThe Natural Language Inference (NLI) task, also known as recognizing textual entailment (RTE),         is to determine whether a premise entails, contradicts or neither entails nor contradicts a hypothesis.\nWe take the French part of the XNLI corpus to form the development and test sets for the NLI task in FLUE.\nThe train set includes 392.7k examples, the dev and test sets comprises 2.5k and 5k examples respectively.\n\nFLUE is an evaluation setup for French NLP systems similar to the popular GLUE benchmark.\nThe goal is to enable further reproducible experiments in the future and to share models and progress on the French language.\nThe tasks and data are obtained from existing works, please refer to our Flaubert paper for a complete list of references.\n", "citation": "\n@inproceedings{conneau2018xnli,\n  author = \"Conneau, Alexis and Rinott, Ruty and Lample, Guillaume and Williams, Adina and Bowman, Samuel R. and Schwenk, Holger and Stoyanov, Veselin\",\n  title = \"XNLI: Evaluating Cross-lingual Sentence Representations\",\n  booktitle = \"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing\",\n  year = \"2018\",\n  publisher = \"Association for Computational Linguistics\",\n  location = \"Brussels, Belgium\",\n}\n\n@misc{le2019flaubert,\n    title={FlauBERT: Unsupervised Language Model Pre-training for French},\n    author={Hang Le and Lo\u00efc Vial and Jibril Frej and Vincent Segonne and Maximin Coavoux and Benjamin Lecouteux and Alexandre Allauzen and Beno\u00eet Crabb\u00e9 and Laurent Besacier and Didier Schwab},\n    year={2019},\n    eprint={1912.05372},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}\n", "homepage": "https://github.com/getalp/Flaubert/tree/master/flue", "license": "", "features": {"premise": {"dtype": "string", "id": null, "_type": "Value"}, "hypothesis": {"dtype": "string", "id": null, "_type": "Value"}, "label": {"num_classes": 3, "names": ["entailment", "neutral", "contradiction"], "names_file": null, "id": null, "_type": "ClassLabel"}}, "supervised_keys": null, "builder_name": "flue", "config_name": "XNLI", "version": {"version_str": "0.0.0", "description": null, "nlp_version_to_prepare": null, "major": 0, "minor": 0, "patch": 0}, "splits": {"train": {"name": "train", "num_bytes": 85809099, "num_examples": 392702, "dataset_name": "flue"}, "validation": {"name": "validation", "num_bytes": 510112, "num_examples": 2490, "dataset_name": "flue"}, "test": {"name": "test", "num_bytes": 1029247, "num_examples": 5010, "dataset_name": "flue"}}, "download_checksums": {"https://dl.fbaipublicfiles.com/XNLI/XNLI-MT-1.0.zip": {"num_bytes": 466098360, "checksum": "f732517ba2fb1d550e9f3c2aabaef6017c91ee2dcec90e878f138764d224db05"}, "https://dl.fbaipublicfiles.com/XNLI/XNLI-1.0.zip": {"num_bytes": 17865352, "checksum": "4ba1d5e1afdb7161f0f23c66dc787802ccfa8a25a3ddd3b165a35e50df346ab1"}}, "download_size": 483963712, "dataset_size": 87348458, "size_in_bytes": 571312170}, "FSE": {"description": "\nFrenchSemEval.\n\nFLUE is an evaluation setup for French NLP systems similar to the popular GLUE benchmark.\nThe goal is to enable further reproducible experiments in the future and to share models and progress on the French language.\nThe tasks and data are obtained from existing works, please refer to our Flaubert paper for a complete list of references.\n", "citation": "\n@inproceedings{segonne2019using,\n  title={Using Wiktionary as a resource for WSD: the case of French verbs},\n  author={Segonne, Vincent and Candito, Marie and Crabb{'e}, Benoit},\n  booktitle={Proceedings of the 13th International Conference on Computational Semantics-Long Papers},\n  pages={259--270},\n  year={2019}\n}\n\n@misc{le2019flaubert,\n    title={FlauBERT: Unsupervised Language Model Pre-training for French},\n    author={Hang Le and Lo\u00efc Vial and Jibril Frej and Vincent Segonne and Maximin Coavoux and Benjamin Lecouteux and Alexandre Allauzen and Beno\u00eet Crabb\u00e9 and Laurent Besacier and Didier Schwab},\n    year={2019},\n    eprint={1912.05372},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}\n", "homepage": "https://github.com/getalp/Flaubert/tree/master/flue", "license": "", "features": {"label": {"dtype": "string", "id": null, "_type": "Value"}, "tokens": {"feature": {"dtype": "string", "id": null, "_type": "Value"}, "length": -1, "id": null, "_type": "Sequence"}, "pos": {"dtype": "int32", "id": null, "_type": "Value"}}, "supervised_keys": null, "builder_name": "flue", "config_name": "FSE", "version": {"version_str": "0.0.0", "description": null, "nlp_version_to_prepare": null, "major": 0, "minor": 0, "patch": 0}, "splits": {"train": {"name": "train", "num_bytes": 65205653, "num_examples": 269821, "dataset_name": "flue"}, "test": {"name": "test", "num_bytes": 845923, "num_examples": 3121, "dataset_name": "flue"}}, "download_checksums": {"http://www.llf.cnrs.fr/dataset/fse/FSE-1.1-10_12_19.tar.gz": {"num_bytes": 38303600, "checksum": "54200bc7c697029f5669df1226edfe6e544af2611c06604c74e33647a0ec7815"}}, "download_size": 38303600, "dataset_size": 66051576, "size_in_bytes": 104355176}, "FWSD.wordnet": {"description": "\nThis is a dataset for the Word Sense Disambiguation of French using Princeton WordNet identifiers.\nIt contains two training corpora : the SemCor and the WordNet Gloss Corpus, both automatically translated from their original English version, and with sense tags automatically aligned.\nIt contains also a test corpus : the task 12 of SemEval 2013, originally sense annotated with BabelNet identifiers, converted into Princeton WordNet 3.0.\n\nFLUE is an evaluation setup for French NLP systems similar to the popular GLUE benchmark.\nThe goal is to enable further reproducible experiments in the future and to share models and progress on the French language.\nThe tasks and data are obtained from existing works, please refer to our Flaubert paper for a complete list of references.\n", "citation": "\n@dataset{loic_vial_2019_3549806,\n  author = {Lo\u00efc Vial},\n  title = {{French Word Sense Disambiguation with Princeton\n  WordNet Identifiers}},\n  month = nov,\n  year = 2019,\n  publisher = {Zenodo},\n  version = {1.0},\n  doi = {10.5281/zenodo.3549806},\n  url = {https://doi.org/10.5281/zenodo.3549806}\n}\n\n@misc{le2019flaubert,\n    title={FlauBERT: Unsupervised Language Model Pre-training for French},\n    author={Hang Le and Lo\u00efc Vial and Jibril Frej and Vincent Segonne and Maximin Coavoux and Benjamin Lecouteux and Alexandre Allauzen and Beno\u00eet Crabb\u00e9 and Laurent Besacier and Didier Schwab},\n    year={2019},\n    eprint={1912.05372},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}\n", "homepage": "https://github.com/getalp/Flaubert/tree/master/flue", "license": "", "features": {"tokens": {"feature": {"dtype": "string", "id": null, "_type": "Value"}, "length": -1, "id": null, "_type": "Sequence"}, "labels": {"feature": {"dtype": "string", "id": null, "_type": "Value"}, "length": -1, "id": null, "_type": "Sequence"}}, "supervised_keys": null, "builder_name": "flue", "config_name": "FWSD.wordnet", "version": {"version_str": "0.0.0", "description": null, "nlp_version_to_prepare": null, "major": 0, "minor": 0, "patch": 0}, "splits": {"train": {"name": "train", "num_bytes": 35954837, "num_examples": 117659, "dataset_name": "flue"}, "test": {"name": "test", "num_bytes": 203245, "num_examples": 306, "dataset_name": "flue"}}, "download_checksums": {"https://zenodo.org/record/3549806/files/wngt.fr.xml": {"num_bytes": 184687997, "checksum": "21cb9c57e1364394f4c77bd592a6f758063b8959d7d65416d3a510ec32129a43"}, "https://zenodo.org/record/3549806/files/semeval2013task12.fr.xml": {"num_bytes": 834622, "checksum": "8e365181d45efe885f908b97040e572bd775dbe515422de73846dbce6dc612b9"}}, "download_size": 185522619, "dataset_size": 36158082, "size_in_bytes": 221680701}, "FWSD.semcor": {"description": "\nThis is a dataset for the Word Sense Disambiguation of French using Princeton WordNet identifiers.\nIt contains two training corpora : the SemCor and the WordNet Gloss Corpus, both automatically translated from their original English version, and with sense tags automatically aligned.\nIt contains also a test corpus : the task 12 of SemEval 2013, originally sense annotated with BabelNet identifiers, converted into Princeton WordNet 3.0.\n\nFLUE is an evaluation setup for French NLP systems similar to the popular GLUE benchmark.\nThe goal is to enable further reproducible experiments in the future and to share models and progress on the French language.\nThe tasks and data are obtained from existing works, please refer to our Flaubert paper for a complete list of references.\n", "citation": "\n@dataset{loic_vial_2019_3549806,\n  author = {Lo\u00efc Vial},\n  title = {{French Word Sense Disambiguation with Princeton\n  WordNet Identifiers}},\n  month = nov,\n  year = 2019,\n  publisher = {Zenodo},\n  version = {1.0},\n  doi = {10.5281/zenodo.3549806},\n  url = {https://doi.org/10.5281/zenodo.3549806}\n}\n\n@misc{le2019flaubert,\n    title={FlauBERT: Unsupervised Language Model Pre-training for French},\n    author={Hang Le and Lo\u00efc Vial and Jibril Frej and Vincent Segonne and Maximin Coavoux and Benjamin Lecouteux and Alexandre Allauzen and Beno\u00eet Crabb\u00e9 and Laurent Besacier and Didier Schwab},\n    year={2019},\n    eprint={1912.05372},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}\n", "homepage": "https://github.com/getalp/Flaubert/tree/master/flue", "license": "", "features": {"tokens": {"feature": {"dtype": "string", "id": null, "_type": "Value"}, "length": -1, "id": null, "_type": "Sequence"}, "labels": {"feature": {"dtype": "string", "id": null, "_type": "Value"}, "length": -1, "id": null, "_type": "Sequence"}}, "supervised_keys": null, "builder_name": "flue", "config_name": "FWSD.semcor", "version": {"version_str": "0.0.0", "description": null, "nlp_version_to_prepare": null, "major": 0, "minor": 0, "patch": 0}, "splits": {"train": {"name": "train", "num_bytes": 16246579, "num_examples": 37176, "dataset_name": "flue"}, "test": {"name": "test", "num_bytes": 203245, "num_examples": 306, "dataset_name": "flue"}}, "download_checksums": {"https://zenodo.org/record/3549806/files/semcor.fr.xml": {"num_bytes": 86041023, "checksum": "582024e3d9a6b3bcf17c4e50570bf8ae94b2339dad767b5c2cda5b8f8ed94a5b"}, "https://zenodo.org/record/3549806/files/semeval2013task12.fr.xml": {"num_bytes": 834622, "checksum": "8e365181d45efe885f908b97040e572bd775dbe515422de73846dbce6dc612b9"}}, "download_size": 86875645, "dataset_size": 16449824, "size_in_bytes": 103325469}}